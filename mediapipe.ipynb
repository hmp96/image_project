{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mediapipe를 이용하여 두 눈 인식 \n",
    "#### colab 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI_MRpBd84m_"
   },
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EU9Bd1Mw9IJL"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vb0UAWQD9IHG"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/개인경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7284,
     "status": "ok",
     "timestamp": 1671599366241,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "-oyCGnO4_-bW",
    "outputId": "5fb3ea2b-43fa-4711-ab9b-9f51adc1cfaa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: mediapipe in /usr/local/lib/python3.8/dist-packages (0.9.0.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.19.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.12.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.21.6)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mediapipe) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hckhFIo-9IFB"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuYOjyim9IC8"
   },
   "outputs": [],
   "source": [
    "def eyesAngle(image_path):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    keypoints = pose.process(image)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    lm = keypoints.pose_landmarks\n",
    "    lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "    x1 = int(lm.landmark[lmPose.LEFT_EYE].x*w)  # 왼쪽 눈 x좌표\n",
    "    y1 = int(lm.landmark[lmPose.LEFT_EYE].y*w)  # 왼쪽 눈 y좌표\n",
    "    x2 = int(lm.landmark[lmPose.RIGHT_EYE].x*w)  # 오른쪽 눈 x좌표\n",
    "    y2 = int(lm.landmark[lmPose.RIGHT_EYE].y*w)  # 오른쪽 눈 y좌표\n",
    "\n",
    "    theta = math.acos((y2-y1)*(-y1) / (math.sqrt((x2-x1)**2+(y2-y1)**2)*y1))\n",
    "    degree = int(180/math.pi) * theta\n",
    "\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmCnCfVB9IAq"
   },
   "outputs": [],
   "source": [
    "def get_eyes_ear(image_path):\n",
    "    global left, right, AVG\n",
    "\n",
    "    image = cv2.imread(image_path)[:, :, ::-1]\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert to RGB\n",
    "    image = np.ascontiguousarray(image)\n",
    "    imgH, imgW, _ = image.shape\n",
    "\n",
    "    chosen_left_eye_idxs = [362, 385, 387, 263, 373, 380]\n",
    "    chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
    "\n",
    "    def distance(point_1, point_2):\n",
    "        dist = sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "        return dist\n",
    "\n",
    " \n",
    "    def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "        try:\n",
    "            coords_points = []\n",
    "        for i in refer_idxs:\n",
    "            lm = landmarks[i]\n",
    "            coord = denormalize_coordinates(lm.x, lm.y,\n",
    "                                            frame_width, frame_height)\n",
    "            coords_points.append(coord)\n",
    "\n",
    "        P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "        P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "        P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "        ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    "\n",
    "    except:\n",
    "        ear = 0.0\n",
    "        coords_points = None\n",
    "\n",
    "    return ear, coords_points\n",
    "\n",
    "\n",
    "  def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "    left_ear, left_lm_coordinates = get_ear(\n",
    "        landmarks,\n",
    "        left_eye_idxs,\n",
    "        image_w,\n",
    "        image_h\n",
    "    )\n",
    "    right_ear, right_lm_coordinates = get_ear(\n",
    "        landmarks,\n",
    "        right_eye_idxs,\n",
    "        image_w,\n",
    "        image_h\n",
    "    )\n",
    "    Avg_EAR = (left_ear + right_ear) / 2.0\n",
    "\n",
    "    return left_ear, right_ear, Avg_EAR, (left_lm_coordinates, right_lm_coordinates)\n",
    "\n",
    "\n",
    "  custom_chosen_lmk_image = image.copy()\n",
    "\n",
    "    with mp_facemesh.FaceMesh(refine_landmarks=True) as face_mesh:\n",
    "        results = face_mesh.process(image).multi_face_landmarks\n",
    "\n",
    "    if results:\n",
    "        for face_id, face_landmarks in enumerate(results):\n",
    "            landmarks = face_landmarks.landmark\n",
    "            left, right, AVG, _ = calculate_avg_ear(\n",
    "              landmarks,\n",
    "              chosen_left_eye_idxs,\n",
    "              chosen_right_eye_idxs,\n",
    "              imgW,\n",
    "              imgH\n",
    "          )\n",
    "\n",
    "    if max(left, right, AVG) > 0.2:\n",
    "        answer = 'wake'\n",
    "    else:\n",
    "        answer = 'sleep'\n",
    "        return answer, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WE1beKnE9H5z"
   },
   "outputs": [],
   "source": [
    "wake_error = ['679.jpg', '88.jpg', '86.jpg', '1027.jpg', '127.jpg', '129.jpg', '168.jpg', '1147.jpg', '933.jpg', '80.jpg', '90.jpg', '16.jpg', '1105.jpg', '1097.jpg', '1100.jpg', '188.jpg', '1048.jpg', '1026.jpg', '744.jpg', '162.jpg', '889.jpg', '126.jpg', '187.jpg', '83.jpg', '124.jpg', '1198.jpg', '1025.jpg', '1068.jpg', '1183.jpg', '1175.jpg', '85.jpg', '178.jpg', '70.jpg', '1018.jpg', '1176.jpg', '89.jpg', '531.jpg', '20.jpg', '1103.jpg', '706.jpg', '985.jpg', '1099.jpg', '1102.jpg', '993.jpg', '345.jpg', '19.jpg', '1098.jpg', '87.jpg', '778.jpg', '1108.jpg', '14.jpg', '1181.jpg', '1024.jpg', '937.jpg', '1101.jpg', '134.jpg', '1017.jpg', '1022.jpg', '135.jpg', '707.jpg', '1071.jpg', '934.jpg', '170.jpg', '515.jpg', '535.jpg', '196.jpg', '1069.jpg', '1016.jpg', '1110.jpg', '82.jpg', '1002.jpg', '1095.jpg', '1094.jpg', '1021.jpg', '829.jpg', '1111.jpg', '1067.jpg', '383.jpg', '23.jpg', '858.jpg', '678.jpg', '1197.jpg', '753.jpg', '618.jpg', '191.jpg', '1072.jpg', '192.jpg', '982.jpg', '1104.jpg', '606.jpg', '1020.jpg', '732.jpg', '1145.jpg', '189.jpg', '133.jpg', '125.jpg', '99.jpg', '534.jpg', '194.jpg', '1112.jpg', '1141.jpg', '456.jpg', '43.jpg', '1127.jpg', '130.jpg', '193.jpg', '573.jpg', '65.jpg', '994.jpg', '628.jpg', '1109.jpg', '91.jpg', '69.jpg', '1140.jpg', '514.jpg', '1146.jpg', '1023.jpg', '128.jpg', '571.jpg', '743.jpg', '186.jpg', '177.jpg', '935.jpg', '116.jpg', '1070.jpg', '1001.jpg', '1003.jpg', '572.jpg', '132.jpg', '346.jpg', '337.jpg', '119.jpg', '71.jpg', '169.jpg', '115.jpg']\n",
    "sleep_error = ['702.jpg', '258.jpg', '41.jpg', '700.jpg', '141.jpg', '27.jpg', '110.jpg', '312.jpg', '392.jpg', '145.jpg', '340.jpg', '45.jpg', '90.jpg', '119.jpg', '291.jpg', '51.jpg', '232.jpg', '84.jpg', '29.jpg', '334.jpg', '150.jpg', '909.jpg', '120.jpg', '352.jpg', '274.jpg', '1065.jpg', '117.jpg', '147.jpg', '96.jpg', '118.jpg', '877.jpg', '226.jpg', '148.jpg', '1068.jpg', '167.jpg', '89.jpg', '351.jpg', '857.jpg', '695.jpg', '47.jpg', '35.jpg', '323.jpg', '179.jpg', '207.jpg', '1006.jpg', '1029.jpg', '321.jpg', '115.jpg', '693.jpg', '144.jpg', '1183.jpg', '890.jpg', '1114.jpg', '197.jpg', '366.jpg', '374.jpg', '195.jpg', '318.jpg', '269.jpg', '146.jpg', '135.jpg', '922.jpg', '138.jpg', '200.jpg', '113.jpg', '52.jpg', '159.jpg', '822.jpg', '280.jpg', '37.jpg', '33.jpg', '256.jpg', '914.jpg', '210.jpg', '747.jpg', '1171.jpg', '95.jpg', '992.jpg', '628.jpg', '281.jpg', '34.jpg', '694.jpg', '102.jpg', '39.jpg', '142.jpg', '1178.jpg', '88.jpg', '698.jpg', '257.jpg', '38.jpg', '1117.jpg', '1010.jpg', '136.jpg', '751.jpg', '696.jpg', '134.jpg', '749.jpg', '101.jpg', '86.jpg', '209.jpg', '1103.jpg', '137.jpg', '818.jpg', '171.jpg', '607.jpg', '927.jpg', '220.jpg', '819.jpg', '384.jpg', '1031.jpg', '350.jpg', '91.jpg', '1165.jpg', '98.jpg', '847.jpg', '70.jpg', '46.jpg', '116.jpg', '1082.jpg', '234.jpg', '1100.jpg', '298.jpg', '177.jpg', '1107.jpg', '140.jpg', '972.jpg', '758.jpg', '1167.jpg', '166.jpg', '125.jpg', '1040.jpg', '916.jpg', '255.jpg', '348.jpg', '1009.jpg', '57.jpg', '601.jpg', '821.jpg', '48.jpg', '746.jpg', '941.jpg', '1056.jpg', '42.jpg', '381.jpg', '253.jpg', '173.jpg', '139.jpg', '254.jpg', '0.jpg', '940.jpg', '354.jpg', '993.jpg', '294.jpg', '1027.jpg', '938.jpg', '165.jpg', '1032.jpg', '30.jpg', '1033.jpg', '97.jpg', '94.jpg', '270.jpg', '156.jpg', '178.jpg', '111.jpg', '333.jpg', '915.jpg', '99.jpg', '697.jpg', '1111.jpg', '373.jpg', '1182.jpg', '353.jpg', '93.jpg', '884.jpg', '1046.jpg', '5.jpg', '944.jpg', '1044.jpg', '606.jpg', '1168.jpg', '49.jpg', '1055.jpg', '92.jpg', '180.jpg', '957.jpg', '155.jpg', '143.jpg', '114.jpg', '1118.jpg', '87.jpg', '172.jpg', '699.jpg', '85.jpg', '174.jpg', '112.jpg', '40.jpg', '997.jpg', '296.jpg', '1064.jpg', '201.jpg', '315.jpg', '371.jpg', '43.jpg', '937.jpg', '182.jpg', '920.jpg', '164.jpg', '399.jpg', '701.jpg', '265.jpg', '252.jpg', '356.jpg', '105.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2cpEw0D9H3s"
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "tmp = []\n",
    "for image in wake_error:\n",
    "    if 80 < eyesAngle(f'wake-samples3/{image}') < 100:\n",
    "        pass\n",
    "    else:\n",
    "        cnt += 1\n",
    "        tmp.append(image)\n",
    "print(cnt)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdjetFtb9H1J"
   },
   "outputs": [],
   "source": [
    "sorted(tmp, key=lambda x: int(x.split('.')[0]))  # 0-199 삭제..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpbi0zT39Hwq"
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "tmp = []\n",
    "for image in sleep_error:\n",
    "    if 80 < eyesAngle(f'sleep-samples3/{image}') < 100:\n",
    "        cnt += 1\n",
    "        tmp.append(image)\n",
    "print(cnt)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4G89Gor9HsS"
   },
   "outputs": [],
   "source": [
    "sorted(tmp, key=lambda x: int(x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qtf9qW8q9Hlx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcFS3nPc9Hjz"
   },
   "source": [
    "### 랜드마크를 좌표로 cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qyyl1-0DAOgb"
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "IMAGE_FILES = os.listdir('wake-samples3')\n",
    "BG_COLOR = (192, 192, 192)  # 회색\n",
    "with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "    wake_landmarks = []\n",
    "    for idx, files in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(f'wake-samples3/{files}')\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        location = []\n",
    "        for landmark in results.pose_world_landmarks.landmark:\n",
    "            location.append([landmark.x, landmark.y, landmark.z])\n",
    "        wake_landmarks.append(np.array(location))\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)\n",
    "\n",
    "IMAGE_FILES = os.listdir('sleep-samples3')\n",
    "BG_COLOR = (192, 192, 192)  # 회색\n",
    "with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.5) as pose:\n",
    "    sleep_landmarks = []\n",
    "    for idx, files in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(f'sleep-samples3/{files}')\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        location = []\n",
    "        for landmark in results.pose_world_landmarks.landmark:\n",
    "            location.append([landmark.x, landmark.y, landmark.z])\n",
    "        sleep_landmarks.append(np.array(location))\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfUXOd1D_rnA"
   },
   "outputs": [],
   "source": [
    "# wake: 0, sleep: 1\n",
    "wake_labels = np.zeros(shape=(1202,))\n",
    "sleep_labels = np.ones(shape=(1202,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHN460sH_rky"
   },
   "outputs": [],
   "source": [
    "print(f'wake_landmarks {np.array(wake_landmarks).shape}, wake_labels {wake_labels.shape}')\n",
    "print(f'sleep_landmarks {np.array(sleep_landmarks).shape}, sleep_labels {sleep_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXo4QKU5_riw"
   },
   "outputs": [],
   "source": [
    "pose_landmarks = np.vstack((np.array(wake_landmarks), np.array(sleep_landmarks)))\n",
    "pose_labels = np.hstack((wake_labels, sleep_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4z8tKJa_reo"
   },
   "outputs": [],
   "source": [
    "print(f'pose_landmarks {pose_landmarks.shape}, pose_labels {pose_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tC_9itIc_rcZ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pose_landmarks, pose_labels, test_size=0.2, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tuet60Li_raS"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((1923, 33, 3, 1))\n",
    "X_test = X_test.reshape((481, 33, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JIevwDc_rTn"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJ0n6C-M_rRf"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 2), padding='valid', input_shape=(33, 3, 1), activation='relu'))\n",
    "# (3, 2)가 가장 잘나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my7-mPUp_-qG"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oHcJf9c_-oW"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abtnJ-Va_-mK"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QRUm-Ke_-j2"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)  # [0.3510306179523468, 0.8274428248405457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyrU_3zb_-de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzIyneS1D7p-"
   },
   "source": [
    "### 눈 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1671600312599,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "u5OQObk2EEW0"
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1671602894777,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "pSM3Gs2hEEUY"
   },
   "outputs": [],
   "source": [
    "def getLandmarks(image_path):\n",
    "\n",
    "    static_image_mode = True\n",
    "    max_num_faces = 10\n",
    "    refine_landmarks = True\n",
    "    min_detection_confidence = 0.5  \n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=static_image_mode, \n",
    "                           max_num_faces=max_num_faces, \n",
    "                           refine_landmarks=refine_landmarks, \n",
    "                           min_detection_confidence=min_detection_confidence) as face_mesh:\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.multi_face_landmarks == None:\n",
    "        landmarks = []\n",
    "    else:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "    return landmarks, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1671602896932,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "cmfIvajnG7v4"
   },
   "outputs": [],
   "source": [
    "def distance(point_1, point_2):\n",
    "    dist = sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1671602897381,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "Ga4b7kjBKb9x"
   },
   "outputs": [],
   "source": [
    "def getEyes(image, landmarks):\n",
    "    r_eye_top = int(landmarks[257].y * image.shape[0])\n",
    "    r_eye_left = int(landmarks[463].x * image.shape[1])\n",
    "    r_eye_bottom = int(landmarks[253].y * image.shape[0])\n",
    "    r_eye_right = int(landmarks[359].x * image.shape[1])\n",
    "    right_eye = image[r_eye_top:r_eye_bottom, r_eye_left:r_eye_right]  \n",
    "\n",
    "    l_eye_top = int(landmarks[27].y * image.shape[0])\n",
    "    l_eye_left = int(landmarks[130].x * image.shape[1])\n",
    "    l_eye_bottom = int(landmarks[23].y * image.shape[0])\n",
    "    l_eye_right = int(landmarks[243].x * image.shape[1])\n",
    "    left_eye = image[l_eye_top:l_eye_bottom, l_eye_left:l_eye_right]\n",
    "\n",
    "  # open/close\n",
    "  coords_points = []\n",
    "    for i in [33,  160, 158, 133, 153, 144, 362, 385, 387, 263, 373, 380]:  # right: 0~5, left: 6~11\n",
    "        landmark = landmarks[i]\n",
    "        coord = denormalize_coordinates(landmark.x, landmark.y, image.shape[1], image.shape[0])  # x, y, w, h\n",
    "        coords_points.append(coord)\n",
    "\n",
    "    R_P2_P6 = distance(coords_points[7], coords_points[11])\n",
    "    R_P3_P5 = distance(coords_points[8], coords_points[10])\n",
    "    R_P1_P4 = distance(coords_points[6], coords_points[9])\n",
    "\n",
    "    R_ear = (R_P2_P6 + R_P3_P5) / (2.0 * R_P1_P4)\n",
    "    \n",
    "    if R_ear >= 0.25:\n",
    "        R_answer = 'open'\n",
    "    else:\n",
    "        R_answer = 'close'\n",
    "\n",
    "    L_P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "    L_P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "    L_P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "    L_ear = (L_P2_P6 + L_P3_P5) / (2.0 * L_P1_P4)\n",
    "    \n",
    "    if L_ear >= 0.25:\n",
    "        L_answer = 'open'\n",
    "    else:\n",
    "        L_answer = 'close'\n",
    "\n",
    "    return right_eye, left_eye, R_answer, L_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1671601095225,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "CtDrxhmJIFdd"
   },
   "outputs": [],
   "source": [
    "image_path = 'wake-samples3/1201.jpg'\n",
    "landmarks, results = getLandmarks(image_path)\n",
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1671601148145,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "_Ws54gtfMI0A"
   },
   "outputs": [],
   "source": [
    "rightEyeImg, leftEyeImg, rightAnswer, leftAnswer = getEyes(image, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1671601150348,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "3IF5_TL6EOBj",
    "outputId": "9be37a1c-914c-4347-e96c-eedde948b36d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAABrklEQVR4nCXSy3EcQQwEURQ+3TPknqSQd7rKD9m8FDnb0wBKB3qQkfHw989vKlTVzAAIDIC7iwhJSplZRBhUpM+3o8ludndmO4AmqyqLIpK5qspGzDnPMcM9IsYYHgpwjFBVVdtd90rfvUWkKJnJhlnYCDNTVTGlortX7iZU1d2pQiEAVfWdd2ZSIKKiCjTQLVLMXWixEoC721VVVC3bzAih0LNqZ8HNzdQDABsC3dnVG0iAZra93SyzzWAW6lBVJ8V9wAJAJUmK8v583ZVVJSIAv4NnxOM8zTDGMWfEHE6EiIqYCLJ6rX2t/Xw+174zq0GHwu1tHseMf/4cbsdxnI/3x+PN3U7ye7jsuz8+7+fH5+t1r9xdApMyMaKGq43ruhav6+v1tV57Lx/jgOpa+7Wu61qv6967ugViqoCKECQgZhrjDbW+1n1XJ1k+Z2QXWfde1/WZtSNs7+UqgDbaRGLoDJiStc10zADALI+hQQNAUlXPtXeXgiS/kQGM8HANw/v5fhxjzlNVq7abUM1whMo5pu+7ivLrx0+SlP7GEGHHcRwzHseYM+Y8bYSq/Afh4x7Eb3g78gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=20x12 at 0x7FD4648F8700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAB10lEQVR4nC2SSW4cQRADmUtVdY9lCXqADf/Rd7/Ab5W1zXTXkkwfRnciCAQpf//8FhEXNTN3NzNVFREBM3MtzjnnnGOM49Z77xFRa621qqoXNQhdpVY3MwAABUISgIioainFzNxqa+0LdF7NzEVTRFUVQGZmJslMARBkrDUXwRRTM2v7dmed53n2m7s7gGTOOQEVkcxkIJKBRHAxQZKUzMhUQEy9FovqX20r1mJmJiWCi0EokSIiIki9x+4iACrQWvNFRHD12fscY44x+jlHMIjJIKmq7l5KqbVuxc0MQhMo0jPzPMfn2/vn5/U8xhgrIiJlkMeYa06IFHd33bZta/Xx8fHSqlVfXH47+tv7++u/1+v1GGMxYGalNU9DJBYpWJEr5phxHMdai98f9Pu3UsxfXl4+Pj5vtxuZZqYi7l5rjUGDDBIARQACIHG9XjVpLk/+4P3oGTS7v0NF7O7NLd2kuN7XXouMWAzfy5jnnFvi4q21bW/Fa2vN3eeM23mMvnqfCVry7ky3Vkqp1S57y4zWqir8188f5CIhIhQwct9bRGTK2Wc/xpyTJIQiYiZ7K5mrNt/35s/PT/H13zlHdKzESmTM6QKpaqJJZArAzNDUUvyyb63V/yDPfwEcKcveAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=20x13 at 0x7FD4648F8BB0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2_imshow(rightEyeImg)\n",
    "cv2_imshow(leftEyeImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671601189218,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "IL368rMVIMOS",
    "outputId": "8b757aa7-0714-446f-e573-36a3920a8af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Eye : open\n",
      "Left Eye : open\n"
     ]
    }
   ],
   "source": [
    "print(f'Right Eye : {rightAnswer}')\n",
    "print(f'Left Eye : {leftAnswer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1671602714719,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "hSnc_9kgNeyY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671601456806,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "m0W8FM0-NeUg"
   },
   "source": [
    "### 눈 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 117184,
     "status": "ok",
     "timestamp": 1671603153669,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "qem_h76jNzC6"
   },
   "outputs": [],
   "source": [
    "for image_path in os.listdir('wake-samples3'):\n",
    "\n",
    "    landmarks, results = getLandmarks(f'wake-samples3/{image_path}')\n",
    "    image = cv2.imread(f'wake-samples3/{image_path}')\n",
    "\n",
    "    if len(landmarks) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        rightEyeImg, leftEyeImg, rightAnswer, leftAnswer = getEyes(image, landmarks)\n",
    "\n",
    "    if rightEyeImg.shape[1] != 0:\n",
    "        if rightAnswer == 'open':\n",
    "            num = len(os.listdir('eyes-samples/open'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', rightEyeImg)\n",
    "        else:\n",
    "            num = len(os.listdir('eyes-samples/close'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', rightEyeImg)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if leftEyeImg.shape[1] != 0:\n",
    "        if leftAnswer == 'open':\n",
    "            num = len(os.listdir('eyes-samples/open'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', leftEyeImg)\n",
    "        else:\n",
    "            num = len(os.listdir('eyes-samples/close'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', leftEyeImg)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 293976,
     "status": "ok",
     "timestamp": 1671603990120,
     "user": {
      "displayName": "현지원",
      "userId": "01017096069007819071"
     },
     "user_tz": -540
    },
    "id": "LxPkeq4ONzA_"
   },
   "outputs": [],
   "source": [
    "for image_path in os.listdir('sleep-samples3'):\n",
    "\n",
    "    landmarks, results = getLandmarks(f'sleep-samples3/{image_path}')\n",
    "    image = cv2.imread(f'sleep-samples3/{image_path}')\n",
    "\n",
    "    if len(landmarks) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        rightEyeImg, leftEyeImg, rightAnswer, leftAnswer = getEyes(image, landmarks)\n",
    "\n",
    "    if rightEyeImg.shape[1] != 0:\n",
    "        if rightAnswer == 'open':\n",
    "            num = len(os.listdir('eyes-samples/open'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', rightEyeImg)\n",
    "        else:\n",
    "            num = len(os.listdir('eyes-samples/close'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', rightEyeImg)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if leftEyeImg.shape[1] != 0:\n",
    "        if leftAnswer == 'open':\n",
    "            num = len(os.listdir('eyes-samples/open'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', leftEyeImg)\n",
    "        else:\n",
    "            num = len(os.listdir('eyes-samples/close'))\n",
    "            cv2.imwrite(f'/content/gdrive/MyDrive/개인경로/{num+1}.jpg', leftEyeImg)\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOQR7R3s6fCEIuQXLGMzCih",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
